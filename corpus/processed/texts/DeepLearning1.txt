Deep Learning Apprentissage
Apprentissage neuronal profond 2IA, 
ENSIAS
Pr.Raddouane chiheb
Mme.hanaa EL Afia

Partie 1: Multi-Layer Perceptron 
(MLP)
Deep Learning Apprentissage
2

Plan
â€¢ Introduction aux RÃ©seaux de Neurones
â€¢ Le Perceptron Simple
â€¢ Le Perceptron Multicouche (MLP)
â€¢ Apprentissage et Optimisation
â€¢ Ã‰valuation et Performances du MLP
Deep Learning Apprentissage
3

Introduction aux RÃ©seaux de Neurones
Un rÃ©seau de neurones artificiels est composÃ© de 
neurones artificiels organisÃ©s en couches :
â€¢ Couche d'entrÃ©e : reÃ§oit les donnÃ©es initiales.
â€¢ Couches cachÃ©es : traitent les informations en 
appliquant des transformations linÃ©aires et non 
linÃ©aires.
â€¢ Couche de sortie : fournit le rÃ©sultat final du 
modÃ¨le.
Chaque neurone effectue une combinaison linÃ©aire 
de ses entrÃ©es, pondÃ©rÃ©e par des poids, Ã  laquelle 
s'ajoute un biais. Cette somme est ensuite passÃ©e Ã  
travers une fonction d'activation pour introduire de 
la non-linÃ©aritÃ©, permettant au rÃ©seau de modÃ©liser 
des relations complexes.
DÃ©finition des RÃ©seaux de Neurones:
Deep Learning Apprentissage
4

DiffÃ©rences entre les RÃ©seaux Biologiques et Artificiels
Bien que les RNA s'inspirent des rÃ©seaux neuronaux biologiques, plusieurs diffÃ©rences 
notables existent :
â€¢ ComplexitÃ© : Les rÃ©seaux biologiques sont immensÃ©ment plus complexes, avec des 
milliards de neurones interconnectÃ©s, tandis que les RNA sont constituÃ©s de quelques 
centaines Ã  des millions de neurones artificiels.
â€¢ Fonctionnement : Les neurones biologiques communiquent via des signaux 
Ã©lectrochimiques, alors que les neurones artificiels utilisent des opÃ©rations 
mathÃ©matiques pour traiter les informations.
â€¢ Apprentissage : Les rÃ©seaux biologiques apprennent de maniÃ¨re adaptative et 
continue, tandis que les RNA nÃ©cessitent des processus d'entraÃ®nement spÃ©cifiques 
avec des ensembles de donnÃ©es Ã©tiquetÃ©es.
Deep Learning Apprentissage
5

Applications et Enjeux des RÃ©seaux de Neurones:
Les RNA ont rÃ©volutionnÃ© de nombreux domaines grÃ¢ce Ã  leur capacitÃ© Ã  modÃ©liser des 
relations complexes :
â€¢ Reconnaissance d'images : Identification d'objets, de visages et de scÃ¨nes.
â€¢ Traitement du langage naturel : Traduction automatique, analyse de sentiments.
â€¢ SantÃ© : Diagnostic assistÃ© par ordinateur, analyse d'images mÃ©dicales.
â€¢ Finance : PrÃ©vision des marchÃ©s, dÃ©tection de fraudes.
Cependant, leur utilisation soulÃ¨ve des enjeux importants :
â€¢ InterprÃ©tabilitÃ© : Les modÃ¨les complexes sont souvent perÃ§us comme des "boÃ®tes 
noires", rendant difficile l'explication de leurs dÃ©cisions.
â€¢ DÃ©pendance aux donnÃ©es : Les RNA nÃ©cessitent de grandes quantitÃ©s de donnÃ©es 
pour un entraÃ®nement efficace.
â€¢ Consommation Ã©nergÃ©tique : L'entraÃ®nement de modÃ¨les de grande taille peut 
Ãªtre Ã©nergivore.
Deep Learning Apprentissage
6

Le Perceptron Simple
Structure dâ€™un neurone artificiel 
Le perceptron simple est un modÃ¨le de neurone artificiel qui classe une 
entrÃ©e en deux catÃ©gories. Voici la structure de ce neurone.
â€¢ ğ‘¬ğ’ğ’•ğ’“Ã©ğ’†ğ’” (ğ’™) : DonnÃ©es introduites dans le neurone, reprÃ©sentant les 
caractÃ©ristiques de l'exemple Ã  classer.
â€¢ ğ‘·ğ’ğ’Šğ’…ğ’” (ğ’˜) : chaque entrÃ©e est associÃ©e Ã  un poids qui dÃ©termine 
l'importance de cette entrÃ©e dans le calcul de la sortie. Les poids sont 
ajustÃ©s lors de l'entraÃ®nement pour minimiser l'erreur.
â€¢ ğ‘©ğ’Šğ’‚ğ’Šğ’” (ğ’ƒ) : ParamÃ¨tre permettant d'ajuster le modÃ¨le
â€¢ Somme pondÃ©rÃ©e :Le neurone calcule la somme des entrÃ©es pondÃ©rÃ©es 
par leurs poids
ğ‘§= à·
ğ‘–=1
ğ‘›
ğ‘¤ğ‘–ğ‘¥ğ‘–+ ğ‘
â€¢ ğ‘­ğ’ğ’ğ’„ğ’•ğ’Šğ’ğ’ ğ’…â€²ğ’‚ğ’„ğ’•ğ’Šğ’—ğ’‚ğ’•ğ’Šğ’ğ’ (ğ’‡) : Introduit une non-linÃ©aritÃ© et dÃ©termine 
si le neurone doit Ãªtre activÃ© ou non 
Deep Learning Apprentissage
7

Algorithme dâ€™Apprentissage du Perceptron
Principe de Fonctionnement
1.Initialisation des poids et du biais.
2.Propagation avant : calcul de la prÃ©diction.
3.Mise Ã  jour des poids si la prÃ©diction est incorrecte.
4.RÃ©pÃ©ter  jusquâ€™Ã  convergence ou atteindre un nombre maximal dâ€™itÃ©rations.
Deep Learning Apprentissage
8

Algorithme dâ€™Apprentissage du Perceptron
EntrÃ©es :
â€¢ ğ‘‹= [ğ‘¥1, ğ‘¥2 , â€¦ â€¦ , ğ‘¥ğ‘›]: donnÃ©es d'entrÃ©e.
â€¢ Y= [ğ‘¦1, ğ‘¦2 , â€¦ â€¦ , ğ‘¦ğ‘š]: Ã©tiquettes ğ‘¦âˆˆ{âˆ’1,1}
â€¢ ğœ‚: taux dâ€™apprentissage (0 < ğœ‚â‰¤1).
â€¢ ğ‘ : nombre dâ€™itÃ©rations.
Initialisation :
â€¢ Poids W= [ğ‘¤1, ğ‘¤2 , â€¦ â€¦ , ğ‘¤ğ‘›]: initialisÃ©s Ã  0 ou des valeurs alÃ©atoires.
â€¢ Biais ğ‘= 0.
Deep Learning Apprentissage
9

Ã‰tapes de lâ€™Algorithme:
Pour ğ‘¡= 1 Ã  ğ‘ (nombre d'itÃ©rations) :
Pour chaque paire (ğ‘¥ğ‘–, ğ‘¦ğ‘–)dans (ğ‘‹, ğ‘Œ) :
1. Calcul de la sortie :
                               ğ‘§= ğ‘Š. ğ‘¥ğ‘–+ ğ‘
                              à·œğ‘¦= àµœ1 
ğ‘ ğ‘– ğ‘§â‰¥0
âˆ’1 
ğ‘ ğ‘– ğ‘§< 0
2.    Mise Ã  jour des poids et biais
â€¢ Si  â€‹ à·ğ‘¦ğ‘–â‰  ğ‘¦ğ‘–(mauvaise prÃ©diction) : 
ğ‘Š= ğ‘Š+ ğœ‚â‹…ğ‘¦ğ‘–â‹…ğ‘¥ğ‘– 
ğ‘ = ğ‘+ ğœ‚â‹…ğ‘¦ğ‘– 
â€¢ Sinon : ne rien changer.
3.    VÃ©rifier la convergence : si toutes les prÃ©dictions sont correctes, arrÃªter.
Deep Learning Apprentissage
10

Sortie :
â€¢ Les poids W et le biais ğ‘ correctement ajustÃ©s.
â€¢ Un modÃ¨le capable de sÃ©parer les donnÃ©es linÃ©airement
Deep Learning Apprentissage
11

Limites du Perceptron Simple : ProblÃ¨me de Non-linÃ©aritÃ©
Le perceptron simple ne peut pas rÃ©soudre des problÃ¨mes qui ne sont pas linÃ©airement 
sÃ©parables. Cela signifie qu'un perceptron simple ne pourra pas apprendre des modÃ¨les 
complexes oÃ¹ les classes ne peuvent pas Ãªtre sÃ©parÃ©es par une seule droite ou hyperplan.
Exemple classique : le problÃ¨me XOR:
EntrÃ©e ğ‘¥1
EntrÃ©e ğ‘¥2
Sortie ğ‘¦
0
0
1
0
1
0
1
0
0
1
1
1
On ne peut pas avoir une 
sÃ©paration linÃ©aire 
Deep Learning Apprentissage
12

Le Perceptron Multicouche (MLP)
Architecture du MLP 
Le Perceptron Multicouche (MLP) est un rÃ©seau de neurones supervisÃ© composÃ© de 
plusieurs couches entiÃ¨rement connectÃ©es. Il est structurÃ© en trois types de couches: 
Couche dâ€™entrÃ©e (Input Layer):
â€¢ Elle reÃ§oit directement les donnÃ©es brutes.
â€¢ Chaque neurone de cette couche reprÃ©sente une caractÃ©ristique ou variable dâ€™entrÃ©e:
â€¢ Exemple (Tabulaire) : 5 variables â†’ 5 neurones.
â€¢ Exemple (Image) : Image 28Ã—28 pixels â†’ 784 neurones.
â€¢ Formule: 
ğ´0 = ğ‘‹= (ğ‘¥1, ğ‘¥2 , â€¦ â€¦ , ğ‘¥ğ‘›)
ğ‘‹est le vecteur dâ€™entrÃ©e.
Deep Learning Apprentissage
13

Couches cachÃ©es (Hidden Layers):
â€¢ Ce sont les couches intermÃ©diaires qui effectuent des transformations 
complexes sur les donnÃ©es.
â€¢ Chaque neurone dâ€™une couche cachÃ©e reÃ§oit les sorties de tous les neurones de 
la couche prÃ©cÃ©dente
â€¢ Le nombre de couches cachÃ©es et de neurones par couche dÃ©termine la 
profondeur et la capacitÃ© dâ€™apprentissage du rÃ©seau.
â€¢ Formule: 
ğ‘(ğ‘™) = ğ‘Š(ğ‘™)ğ´(ğ‘™âˆ’1) + ğ‘ğ‘™
ğ´ğ‘™= ğ‘“ğ‘§ğ‘™
Deep Learning Apprentissage
14

Couche de sortie (Output Layer):
â€¢ Produit la prÃ©diction finale.
â€¢ Nombre de neurones : DÃ©pend du problÃ¨me.
â€¢ Classification binaire â†’ 1 neurone (SigmoÃ¯de).
â€¢ Classification multiclasse â†’ ğ¾ neurones (Softmax).
â€¢ RÃ©gression â†’ 1 neurone (sans activation ou ReLU).
ğ‘(ğ‘™) = ğ‘Š(ğ‘™)ğ´(ğ‘™âˆ’1) + ğ‘ğ‘™
à· ğ‘Œ= ğ‘“ğ‘§ğ‘™
Deep Learning Apprentissage
15

Propagation Avant (Forward Propagation) dans un MLP
La Propagation Avant est le processus par lequel une entrÃ©e traverse le rÃ©seau 
pour produire une sortie. Chaque neurone applique une transformation affine 
suivie d'une fonction d'activation non linÃ©aire.
Ã‰tape 1 : Calcul de la Combinaison LinÃ©aire:
Pour chaque couche ğ‘™âˆˆ{1,2, â€¦ , ğ¿} ,on calcule la somme pondÃ©rÃ©e des activations 
de la couche prÃ©cÃ©dente :  
ğ‘(ğ‘™) = ğ‘Š(ğ‘™)ğ´(ğ‘™âˆ’1) + ğ‘ğ‘™
Ã‰tape 2 : Application de la Fonction dâ€™Activation:
La sortie du neurone est obtenue en appliquant la fonction dâ€™activation :
ğ´ğ‘™= ğ‘“ğ‘§ğ‘™
Deep Learning Apprentissage
16

Ã‰tape 3 : Calcul de la Sortie
Ã€ la couche de sortie (l=L), on applique la derniÃ¨re transformation :
à· ğ‘Œ= ğ‘“ğ‘Š(ğ‘™)ğ´(ğ‘™âˆ’1) + ğ‘ğ‘™
La Propagation Avant suit ces Ã©tapes :
1. Combinaison linÃ©aire : somme pondÃ©rÃ©e des entrÃ©es.
2. Non-linÃ©aritÃ© : activation avec ğ‘“(ğ‘§).
3. Propagation de couche en couche jusquâ€™Ã  la sortie.
Ce processus transforme les entrÃ©es en sorties prÃ©dictives Ã  travers des transformations 
successives.
Deep Learning Apprentissage
17

Deep Learning Apprentissage
18

Fonctions dâ€™Activation
Les fonctions dâ€™activation jouent un rÃ´le essentiel dans les rÃ©seaux de neurones 
artificiels, en particulier dans les Perceptrons Multicouches (MLP). Elles permettent au 
rÃ©seau de modÃ©liser des relations complexes et non linÃ©aires.
Principaux RÃ´les des Fonctions dâ€™Activation:
â€¢ Introduire de la Non-linÃ©aritÃ©
â€¢ Adapter la Sortie aux ProblÃ¨mes SpÃ©cifiques
â€¢ Optimiser la Convergence de lâ€™Apprentissage
â€¢ ConsidÃ©rations sur le Temps de Calcul
Deep Learning Apprentissage
19

Fonction dâ€™Activation SigmoÃ¯de:
La fonction sigmoÃ¯de est une fonction d'activation classique utilisÃ©e dans les rÃ©seaux 
de neurones, surtout pour la classification binaire. Elle permet de transformer toute 
valeur rÃ©elle en un nombre compris entre 0 et 1, ce qui la rend idÃ©ale pour prÃ©dire 
des probabilitÃ©s.
Deep Learning Apprentissage
20

Exemple:
Imaginons un modÃ¨le de rÃ©seau de neurones qui doit prÃ©dire si un email est un spam (classe 1) ou 
non-spam (classe 0). Le modÃ¨le reÃ§oit une entrÃ©e X (qui pourrait Ãªtre, par exemple, un ensemble 
de caractÃ©ristiques extraites du contenu de l'email, comme la frÃ©quence de certains mots, la 
longueur de l'email, etc.).
ConsidÃ©rons :
â€¢ Poids ğ‘Š= [1.2, âˆ’0.8]
â€¢ Biais ğ‘= 0.5
â€¢ EntrÃ©e ğ‘‹= [2,3]
Ã‰tape 1 : Calcul de la somme pondÃ©rÃ©e:
ğ‘§= (1.2 Ã— 2) + (âˆ’0.8 Ã— 3) + 0.5 = 2.4 âˆ’2.4 + 0.5 = 0.5
Ã‰tape 2 : Application de la fonction sigmoÃ¯de
ğœ(0.5) â‰ˆ0.622
La sortie du neurone, aprÃ¨s avoir appliquÃ© la fonction sigmoÃ¯de, est environ 0.621. Cela signifie 
que, selon le modÃ¨le, la probabilitÃ© que que l'email soit un spam est d'environ 62.1%.
Deep Learning Apprentissage
21

Fonction dâ€™Activation Tanh (Tangente Hyperbolique):
La fonction Tanh (ou tangente hyperbolique) est une amÃ©lioration de la fonction 
sigmoÃ¯de. Contrairement Ã  la sigmoÃ¯de qui gÃ©nÃ¨re des sorties entre 0 et 1, la fonction 
Tanh produit des sorties entre -1 et 1, ce qui la rend plus adaptÃ©e pour des donnÃ©es 
centrÃ©es autour de zÃ©ro.
Deep Learning Apprentissage
22

Exemple:
ConsidÃ©rons :
â€¢ Poids ğ‘Š= [0.5, âˆ’1]
â€¢ Biais ğ‘= 0.2
â€¢ EntrÃ©e ğ‘‹= [1,2]
Ã‰tape 1 : Calcul de la somme pondÃ©rÃ©e:
ğ‘§= 0.5 Ã— 2 + âˆ’1 Ã— 3 + 0.2 = âˆ’1.3.
Ã‰tape 2 : Application de la fonction  Tanh 
tanh âˆ’1.3 â‰ˆâˆ’0.861
La sortie du neurone est âˆ’ğŸ. ğŸ–ğŸ”ğŸ, ce qui indique une forte appartenance Ã  la classe 
nÃ©gative.
Deep Learning Apprentissage
23

Fonction dâ€™Activation ReLU:
La ReLU est aujourdâ€™hui lâ€™une des fonctions dâ€™activation les plus utilisÃ©es dans les 
rÃ©seaux de neurones, notamment pour les rÃ©seaux profonds. Elle est simple, rapide Ã  
calculer et efficace pour rÃ©soudre le problÃ¨me du gradient qui disparaÃ®t.
Deep Learning Apprentissage
24

Fonction dâ€™Activation Softmax
La Softmax est une fonction dâ€™activation utilisÃ©e principalement dans la couche de 
sortie des rÃ©seaux de neurones pour les problÃ¨mes de classification multiclasse. Elle 
transforme un vecteur de valeurs rÃ©elles en un vecteur de probabilitÃ©s dont la 
somme est Ã©gale Ã  1.
Deep Learning Apprentissage
25

Apprentissage et Optimisation
Fonction de Perte (Loss Function)
DÃ©finition :
La fonction de perte mesure lâ€™Ã©cart entre la prÃ©diction du modÃ¨le à·œğ‘¦ et la valeur rÃ©elle 
ğ‘¦ pour chaque observation individuelle. Son objectif est de quantifier lâ€™erreur commise 
afin de guider lâ€™apprentissage du modÃ¨le.
RÃ´le et Importance de la Fonction de Perte:
â€¢ Mesure de la Performance du ModÃ¨le
â€¢ Guide lâ€™Optimisation du ModÃ¨le
â€¢ Influence sur la Vitesse et la QualitÃ© de l'Apprentissage
Deep Learning Apprentissage
26

Types de Fonctions de Perte selon les ProblÃ¨mes
RÃ©gression (ProblÃ¨me de PrÃ©diction Continue avec l'Erreur Quadratique Moyenne (MSE)):
L'Erreur Quadratique Moyenne (MSE) est une fonction de perte couramment utilisÃ©e pour 
les problÃ¨mes de rÃ©gression. Elle mesure la moyenne des carrÃ©s des Ã©carts entre les valeurs 
prÃ©dites et les valeurs rÃ©elles, pÃ©nalisant fortement les grandes erreurs, Sa formule est la 
suivante: 
ğ¿à·œğ‘¦, ğ‘¦= (à·œğ‘¦âˆ’ğ‘¦)2
â€¢ ğ‘¦: Valeur rÃ©elle
â€¢ à·œğ‘¦:Valeur prÃ©dite par le modÃ¨le
â€¢ n:Nombre d'exemples dans le jeu de donnÃ©es
Deep Learning Apprentissage
27

Exemple : PrÃ©diction du Prix des Maisons
Imaginons que nous essayons de prÃ©dire le prix d'une maison en fonction de ses 
caractÃ©ristiques, comme la surface en mÃ¨tres carrÃ©s. Ce problÃ¨me de rÃ©gression vise Ã  
prÃ©dire une valeur continue (prix de la maison) Ã  partir de certaines donnÃ©es d'entrÃ©e
MSE=100 000 000
Erreur Quadratique Moyenne (MSE) est de 100,000,000, ce qui signifie qu'en moyenne, 
chaque prÃ©diction de prix est dÃ©viÃ©e de 10,000 â‚¬ par rapport Ã  la rÃ©alitÃ© (en termes 
absolus).
Surface (mÂ²)
Prix rÃ©el (en â‚¬)
Prix prÃ©dit (en â‚¬)
80
250,000
240,000
100
300,000
310,000
120
350,000
340,000
150
450,000
440,000
Deep Learning Apprentissage
28

Classification Binaire (Entropie CroisÃ©e Binaire (Binary Cross-Entropy))
L'entropie croisÃ©e binaire est utilisÃ©e lorsque le problÃ¨me de classification comporte deux 
classes (0 ou 1).
Formule:
ğ¿à·œğ‘¦, ğ‘¦= âˆ’(ğ‘¦. log à·œğ‘¦+ (1 âˆ’ğ‘¦) log(1 âˆ’à·œğ‘¦))
â€¢ ğ‘¦ : Ã‰tiquette rÃ©elle (0 ou 1)
â€¢ à·œğ‘¦ :probabilitÃ© prÃ©dite que lâ€™Ã©chantillon appartienne Ã  la classe 1
Plus la prÃ©diction est proche de la vÃ©ritÃ©, plus la perte est faible.
Deep Learning Apprentissage
29

Exemple : DÃ©tection de Spam
Analyse :
â€¢ Email A : Bonne prÃ©diction â†’ Perte faible
â€¢ Email B : Mauvaise prÃ©diction â†’ Perte Ã©levÃ©e
â€¢ Email C : Mauvaise prÃ©diction â†’ Perte Ã©levÃ©e
â€¢ Email D : Bonne prÃ©diction â†’ Perte faible
Email
Vraie Classe 
ProbabilitÃ© prÃ©dite 
Perte (BCE)
A
spam
0.9
0.105
B
spam
0.1
2.302
C
Non spam
0.8
1.609
D
Non spam
0.05
0.051
Deep Learning Apprentissage
30

Classification Multiclasse Entropie CroisÃ©e CatÃ©gorique (Categorical Cross-Entropy) 
UtilisÃ©e pour les problÃ¨mes oÃ¹ il y a plus de deux classes. Elle compare un vecteur one-hot 
des vraies classes avec les probabilitÃ©s prÃ©dites.
 Formule:
ğ¿à·œğ‘¦, ğ‘¦= âˆ’à·
ğ‘—=1
ğ¶
ğ‘¦ğ‘—. log à·ğ‘¦ğ‘—
â€¢ ğ‘¦ : Ã‰tiquette rÃ©elle 
â€¢ à·œğ‘¦ :probabilitÃ© prÃ©dite pour classe j
â€¢ C: nombre de classe
Explication:
â€¢ One-hot encoding est utilisÃ© pour ğ‘¦ 
â€¢ Seule la probabilitÃ© de la classe correcte impacte la perte.
Deep Learning Apprentissage
31

Exemple : Reconnaissance de Chiffres (0 Ã  9):
Un modÃ¨le doit prÃ©dire le chiffre reprÃ©sentÃ© par cette image:
Calcul de la Perte :
ğ¿à·œğ‘¦, ğ‘¦= 0.511
Le modÃ¨le prÃ©dit la classe 2 avec 60% de probabilitÃ© â†’ Perte modÃ©rÃ©e.
Classe
0
1
2
3
4
5
6
7
8
9
ğ‘¦
0
0
1
0
0
0
0
0
0
0
à·œğ‘¦ 
0.01
0.05
0.6
0.1
0.05
0.04
0.03
0.06
0.03
0.03
Deep Learning Apprentissage
32

L'algorithme de rÃ©tropropagation est un Ã©lÃ©ment fondamental dans l'entraÃ®nement des 
rÃ©seaux de neurones multicouches (MLP). Il permet de calculer efficacement les 
gradients de la fonction de perte par rapport aux poids et biais du rÃ©seau, afin de les 
mettre Ã  jour et amÃ©liorer les performances du modÃ¨le.
Principe de la RÃ©tropropagation:
L'objectif est de minimiser la fonction de perte en ajustant les poids W et les biais b du 
rÃ©seau
Deux grandes Ã©tapes :
1. Propagation avant (Forward Pass) :
 Calcul des sorties du rÃ©seau pour une entrÃ©e donnÃ©e.
2. Propagation arriÃ¨re (Backward Pass) :
       Calcul des gradients de la fonction de perte par rapport aux poids et biais
Algorithme de RÃ©tropropagation (Backpropagation)
Deep Learning Apprentissage
33

Ã‰tapes de la RÃ©tropropagation:
Ã‰tape 1 :Erreur de la couche de sortie
 On calcule lâ€™erreur entre la sortie prÃ©dite à·œğ‘¦  â€‹et la sortie rÃ©elle ğ‘¦
ğ›¿ğ¿= ğœ•ğ¿
ğœ•ğ‘§ğ‘™= (ğ´ğ¿âˆ’ğ‘¦) âŠ™ğ‘“â€²(ğ‘§ğ‘™)
Ã‰tape 2 Erreur des couches cachÃ©es:
ğ›¿ğ‘™ = (ğ‘Š(ğ‘™+1)ğ‘‡ğ›¿ğ‘™+1) âŠ™ğ‘“â€²(ğ‘§ğ‘™)
Ã‰tape 3: Calcul des gradients
ğœ•ğ¿
ğœ•ğ‘Šğ‘™= ğ›¿ğ‘™ğ´ğ‘™âˆ’1 ğ‘‡
ğœ•ğ¿
ğœ•ğ‘ğ‘™= ğ›¿ğ‘™
Ã‰tape 4 Mise Ã  Jour des Poids et Biais
ğ‘Šğ‘™= ğ‘Šğ‘™âˆ’ğœ‚ğœ•ğ¿
ğœ•ğ‘Šğ‘™
 
ğ‘ğ‘™= ğ‘ğ‘™âˆ’ğœ‚ğœ•ğ¿
ğœ•ğ‘ğ‘™
Deep Learning Apprentissage
34

Points ClÃ©s:
â€¢La propagation avant calcule la sortie du rÃ©seau.
â€¢La propagation arriÃ¨re calcule comment ajuster les poids pour rÃ©duire l'erreur.
â€¢La descente de gradient met Ã  jour les paramÃ¨tres pour amÃ©liorer les performances.
â€¢L'efficacitÃ© de la rÃ©tropropagation dÃ©pend du choix des fonctions dâ€™activation et du taux 
dâ€™apprentissage. 
Deep Learning Apprentissage
35

Lâ€™optimisation consiste Ã  ajuster les poids et les biais dâ€™un rÃ©seau de neurones pour minimiser 
la fonction de perte . Cela permet au modÃ¨le dâ€™amÃ©liorer ses prÃ©dictions
Gradient Descent:
Principe :
 Met Ã  jour les paramÃ¨tres dans la direction opposÃ©e au gradient de la fonction de perte.
Formule :
â€¢ ğœƒ: Poids et biais.
â€¢ ğœ‚: Taux dâ€™apprentissage (learning rate).
â€¢ âˆ‡ ğœƒğ¿ğœƒ: Gradient de la perte.
Optimisation
Deep Learning Apprentissage
36

Variantes :
â€¢ Batch Gradient Descent : Calcul avec tout le dataset.
â€¢ Stochastic Gradient Descent (SGD) : Mise Ã  jour Ã  chaque exemple.
â€¢ Mini-Batch Gradient Descent : Mise Ã  jour par petit lot dâ€™exemples.
 Algorithmes AvancÃ©s
â€¢ Momentum : AccÃ©lÃ¨re la convergence en ajoutant un terme de vitesse.
â€¢ RMSProp : Ajuste le taux dâ€™apprentissage pour chaque paramÃ¨tre.
â€¢ Adam : Combine Momentum et RMSProp, adaptatif et rapide.
Deep Learning Apprentissage
37

Objectif:
La rÃ©gularisation est une technique utilisÃ©e pour rÃ©duire le surapprentissage (overfitting) et 
amÃ©liorer la capacitÃ© du modÃ¨le Ã  se gÃ©nÃ©raliser sur des donnÃ©es non vues. En ajoutant une 
pÃ©nalitÃ© aux poids du modÃ¨le, elle aide Ã  Ã©viter qu'il ne s'adapte trop prÃ©cisÃ©ment aux 
donnÃ©es d'entraÃ®nement, y compris leur bruit.
ProblÃ¨me du Surapprentissage:
Le surapprentissage survient lorsque le modÃ¨le s'adapte trop prÃ©cisÃ©ment aux donnÃ©es 
d'entraÃ®nement, capturant Ã  la fois les relations sous-jacentes et le bruit prÃ©sent dans les 
donnÃ©es. Cela conduit Ã  un modÃ¨le performant sur les donnÃ©es dâ€™entraÃ®nement mais moins 
efficace sur des donnÃ©es nouvelles.
SymptÃ´mes du surapprentissage :
TrÃ¨s bonne performance sur les donnÃ©es dâ€™entraÃ®nement, mais mauvaise performance sur les 
donnÃ©es de test.
RÃ©gularisation
Deep Learning Apprentissage
38

MÃ©thodes de RÃ©gularisation:
Les techniques de rÃ©gularisation agissent principalement en modifiant la fonction de perte 
ğ¿(ğ‘¤) ,oÃ¹ ğ‘¤ reprÃ©sente les poids du modÃ¨le. Voici les principales mÃ©thodes de rÃ©gularisation: 
RÃ©gularisation L1 (Lasso):
Principe :
Ajout dâ€™une pÃ©nalitÃ© proportionnelle Ã  la somme des valeurs absolues des poids ğ‘Š.
Formule de la fonction de perte:
ğ¿ğ‘¤= ğ¿ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ğ‘’ğ‘¤+ ğœ†à·
ğ‘–=1
ğ‘›
ğ‘¤ğ‘–
â€¢ ğ¿ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ğ‘’ğ‘¤:Fonction de perte sans rÃ©gularisation 
â€¢ ğœ† : HyperparamÃ¨tre qui contrÃ´le lâ€™importance de la rÃ©gularisation.
Effet :
â€¢ Encourage les poids ğ‘¤ğ‘– â€‹ Ã  devenir exactement Ã©gaux Ã  zÃ©ro, ce qui peut Ã©liminer des 
caractÃ©ristiques inutiles.
â€¢ Convient pour des modÃ¨les oÃ¹ certaines caractÃ©ristiques sont peu informatives (sparse 
models).
Deep Learning Apprentissage
39

RÃ©gularisation L2 (Ridge):
Principe :
Ajout dâ€™une pÃ©nalitÃ© proportionnelle Ã  la somme des carrÃ©s des poids W.
Formule de la fonction de perte :
ğ¿ğ‘¤= ğ¿ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ğ‘’ğ‘¤+ ğœ†à·
ğ‘–=1
ğ‘›
ğ‘¤ğ‘–2
Effet :
â€¢ RÃ©duit les valeurs des poids ğ‘¤ğ‘–, mais ne les force pas Ã  Ãªtre nuls.
â€¢ PrivilÃ©gie un modÃ¨le plus stable en limitant les poids extrÃªmes, ce qui amÃ©liore la 
gÃ©nÃ©ralisation.
Deep Learning Apprentissage
40

Dropout:
Principe :
Pendant l'entraÃ®nement, dÃ©sactiver alÃ©atoirement une fraction des neurones Ã  chaque 
itÃ©ration pour rÃ©duire la dÃ©pendance du modÃ¨le Ã  des combinaisons spÃ©cifiques de 
neurones.
Formule conceptuelle :
â„ğ‘–
ğ‘‘ğ‘Ÿğ‘œğ‘ğ‘œğ‘¢ğ‘¡= â„ğ‘–. ğ‘Ÿğ‘– ğ‘Ÿğ‘–âˆ¼Bernoulli(p)
â„ğ‘– : Activation du neurone ğ‘–.
ğ‘Ÿğ‘– : Masque binaire (0 ou 1) gÃ©nÃ©rÃ© alÃ©atoirement avec une probabilitÃ© ğ‘ de garder le 
neurone actif.
Effet :
â€¢ Force le modÃ¨le Ã  apprendre des reprÃ©sentations redondantes et plus robustes.
â€¢ RÃ©duit le surapprentissage dans les rÃ©seaux profonds.
Deep Learning Apprentissage
41

Early Stopping
Principe :
ArrÃªter l'entraÃ®nement lorsque la performance sur les donnÃ©es de validation cesse 
de   sâ€™amÃ©liorer.
ProcÃ©dure :
â€¢ Suivre lâ€™Ã©volution de la fonction de perte sur les donnÃ©es de validation.
â€¢ Interrompre lâ€™entraÃ®nement lorsque la perte de validation commence Ã  
augmenter, ce qui indique un surapprentissage.
Effet :
â€¢ EmpÃªche le modÃ¨le de s'adapter trop aux donnÃ©es d'entraÃ®nement.
Deep Learning Apprentissage
42

Ã‰valuation et Performances
Pour Ã©valuer un MLP, on utilise des mÃ©triques adaptÃ©es aux tÃ¢ches :
RÃ©gression :
â€¢ MAE (Erreur Absolue Moyenne)
â€¢ RÂ² (Coefficient de DÃ©termination)
Classification Binaire :
PrÃ©cision, Rappel et F1-Score :
Exemples des formules pour la classe positive (ğ‘¦= 1)
Classification Multiclasse :
Exactitude (Accuracy) :
Mesures de Performance 
Deep Learning Apprentissage
43

1.RÃ©gularisation 
2.Dropout 
3.Early Stopping 
4.Augmentation des DonnÃ©es
 
5.RÃ©duction de la ComplexitÃ© du ModÃ¨le 
6.HyperparamÃ¨tres 
Solution de Surapprentissage
Deep Learning Apprentissage
44

â€¢ Taille et Nombre des Couches CachÃ©es 
â€¢ Fonction dâ€™Activation 
â€¢ Taux d'Apprentissage (Learning Rate) 
â€¢ Taille de Batch (Batch Size) 
â€¢ Nombre dâ€™Ã‰poques 
â€¢ MÃ©thode de RÃ©gularisation 
HyperparamÃ¨tres 
Deep Learning Apprentissage
45
